{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FixedLocator, FuncFormatter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import scipy as sp\n",
    "from scipy.constants import hbar, physical_constants\n",
    "from scipy.stats import chi2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Retrieve physical constants\n",
    "e_au = physical_constants[\"atomic unit of charge\"][0]\n",
    "\n",
    "# Conversion factors\n",
    "s_to_eVminus1 = e_au / hbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data folder\n",
    "data_folder = \"sgrdata\"\n",
    "day81_folder = os.path.join(data_folder, \"day81\")\n",
    "day82_folder = os.path.join(data_folder, \"day82\")\n",
    "\n",
    "# Define the file paths for day 81\n",
    "file_dark_day81 = os.path.join(day81_folder, \"dark.npy\")\n",
    "file_blue1_day81 = os.path.join(day81_folder, \"blue1.npy\")\n",
    "file_blue2_day81 = os.path.join(day81_folder, \"blue2.npy\")\n",
    "file_red1_day81 = os.path.join(day81_folder, \"red1.npy\")\n",
    "file_red2_day81 = os.path.join(day81_folder, \"red2.npy\")\n",
    "\n",
    "# Define the file paths for day 82\n",
    "file_dark_day82 = os.path.join(day82_folder, \"dark.npy\")\n",
    "file_blue1_day82 = os.path.join(day82_folder, \"blue1.npy\")\n",
    "file_blue2_day82 = os.path.join(day82_folder, \"blue2.npy\")\n",
    "file_red1_day82 = os.path.join(day82_folder, \"red1.npy\")\n",
    "file_red2_day82 = os.path.join(day82_folder, \"red2.npy\")\n",
    "\n",
    "# Read the data for day 81\n",
    "data_dark_day81 = np.load(file_dark_day81)\n",
    "data_blue1_day81 = np.load(file_blue1_day81)\n",
    "data_blue2_day81 = np.load(file_blue2_day81)\n",
    "data_red1_day81 = np.load(file_red1_day81)\n",
    "data_red2_day81 = np.load(file_red2_day81)\n",
    "\n",
    "# Read the data for day 82\n",
    "data_dark_day82 = np.load(file_dark_day82)\n",
    "data_blue1_day82 = np.load(file_blue1_day82)\n",
    "data_blue2_day82 = np.load(file_blue2_day82)\n",
    "data_red1_day82 = np.load(file_red1_day82)\n",
    "data_red2_day82 = np.load(file_red2_day82)\n",
    "\n",
    "# Convert dark data to DataFrames and add a sigma column with default value 3\n",
    "df_dark_day81 = pd.DataFrame(data_dark_day81, columns=[\"time\", \"phi\"])\n",
    "df_dark_day81[\"sigma\"] = 3 # Add sigma column with default value 3\n",
    "\n",
    "df_dark_day82 = pd.DataFrame(data_dark_day82, columns=[\"time\", \"phi\"])\n",
    "df_dark_day82[\"sigma\"] = 3 # Add sigma column with default value 3\n",
    "\n",
    "# Convert blue and red data to DataFrames for day 81\n",
    "df_blue1_day81 = pd.DataFrame(data_blue1_day81, columns=[\"time\", \"phi\"])\n",
    "df_blue2_day81 = pd.DataFrame(data_blue2_day81, columns=[\"time\", \"phi\"])\n",
    "df_red1_day81 = pd.DataFrame(data_red1_day81, columns=[\"time\", \"phi\"])\n",
    "df_red2_day81 = pd.DataFrame(data_red2_day81, columns=[\"time\", \"phi\"])\n",
    "\n",
    "# Convert blue and red data to DataFrames for day 82\n",
    "df_blue1_day82 = pd.DataFrame(data_blue1_day82, columns=[\"time\", \"phi\"])\n",
    "df_blue2_day82 = pd.DataFrame(data_blue2_day82, columns=[\"time\", \"phi\"])\n",
    "df_red1_day82 = pd.DataFrame(data_red1_day82, columns=[\"time\", \"phi\"])\n",
    "df_red2_day82 = pd.DataFrame(data_red2_day82, columns=[\"time\", \"phi\"])\n",
    "\n",
    "# Create combined blue and red DataFrames for day 81\n",
    "df_blue_day81 = pd.DataFrame({\n",
    "    \"time\": (df_blue1_day81[\"time\"] + df_blue2_day81[\"time\"]) / 2,\n",
    "    \"phi\": (df_blue1_day81[\"phi\"] + df_blue2_day81[\"phi\"]) / 2,\n",
    "    \"sigma\": abs(df_blue1_day81[\"phi\"] - df_blue2_day81[\"phi\"]) / 2\n",
    "})\n",
    "\n",
    "df_red_day81 = pd.DataFrame({\n",
    "    \"time\": (df_red1_day81[\"time\"] + df_red2_day81[\"time\"]) / 2,\n",
    "    \"phi\": (df_red1_day81[\"phi\"] + df_red2_day81[\"phi\"]) / 2,\n",
    "    \"sigma\": abs(df_red1_day81[\"phi\"] - df_red2_day81[\"phi\"]) / 2\n",
    "})\n",
    "\n",
    "# Create combined blue and red DataFrames for day 82\n",
    "df_blue_day82 = pd.DataFrame({\n",
    "    \"time\": (df_blue1_day82[\"time\"] + df_blue2_day82[\"time\"]) / 2,\n",
    "    \"phi\": (df_blue1_day82[\"phi\"] + df_blue2_day82[\"phi\"]) / 2,\n",
    "    \"sigma\": abs(df_blue1_day82[\"phi\"] - df_blue2_day82[\"phi\"]) / 2\n",
    "})\n",
    "\n",
    "df_red_day82 = pd.DataFrame({\n",
    "    \"time\": (df_red1_day82[\"time\"] + df_red2_day82[\"time\"]) / 2,\n",
    "    \"phi\": (df_red1_day82[\"phi\"] + df_red2_day82[\"phi\"]) / 2,\n",
    "    \"sigma\": abs(df_red1_day82[\"phi\"] - df_red2_day82[\"phi\"]) / 2\n",
    "})\n",
    "\n",
    "# Combine dark, blue, and red DataFrames for day 81\n",
    "df_total_day81 = pd.concat([df_dark_day81, df_blue_day81, df_red_day81])\n",
    "df_total_day81 = df_total_day81.sort_values(by=\"time\").reset_index(drop=True)\n",
    "\n",
    "# Combine dark, blue, and red DataFrames for day 82\n",
    "df_total_day82 = pd.concat([df_dark_day82, df_blue_day82, df_red_day82])\n",
    "df_total_day82 = df_total_day82.sort_values(by=\"time\").reset_index(drop=True)\n",
    "\n",
    "# Combine day 81 and day 82 DataFrames\n",
    "df_total = pd.concat([df_total_day81, df_total_day82])\n",
    "df_total = df_total.sort_values(by=\"time\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Extract data\n",
    "time = df_total[\"time\"].values\n",
    "phi = df_total[\"phi\"].values\n",
    "sigma = df_total[\"sigma\"].values\n",
    "\n",
    "# Plot the data\n",
    "plt.plot(time, phi, \"-x\", color=\"blue\", label=\"Data\")\n",
    "\n",
    "# Add error bars\n",
    "plt.errorbar(time, phi, yerr=sigma, fmt=\"none\", ecolor=\"red\", capsize=2, label=\"Error\")\n",
    "\n",
    "# Set the labels and title\n",
    "plt.xlabel(\"UT Hour\", fontsize=12)\n",
    "plt.ylabel(r\"Angle ($^\\circ$)\", fontsize=12)\n",
    "plt.title(\"Polarization Angle versus Time\", fontsize=14)\n",
    "\n",
    "# Set the legend\n",
    "plt.legend(loc=\"upper right\", fontsize=10)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the pickle file\n",
    "interp_file = os.path.join(data_folder, \"interp_datanew.pkl\")\n",
    "with open(interp_file, \"rb\") as f:\n",
    "    interp_data = pickle.load(f)\n",
    "\n",
    "# Extract the parameters\n",
    "params_data = np.loadtxt(\"paralist_all_SgrltNE.dat\")\n",
    "params = []\n",
    "for i in range(len(params_data) // 20):\n",
    "    m = params_data[i * 20, 1]\n",
    "    epsilon = params_data[i * 20, 2]\n",
    "    params.append([m, epsilon])\n",
    "\n",
    "# Convert to numpy array\n",
    "params = np.array(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mass_to_period(m):\n",
    "    # Convert mass to period\n",
    "    period_hr = 2 * np.pi / m / s_to_eVminus1 / 3600\n",
    "    return period_hr\n",
    "\n",
    "def period_to_mass(period_hr):\n",
    "    # Convert period to mass\n",
    "    m = 2 * np.pi / period_hr / s_to_eVminus1 / 3600\n",
    "    return m\n",
    "\n",
    "def extract_data_obs(data):\n",
    "    # Extract data from observation\n",
    "    times_obs = data[\"time\"].to_numpy()\n",
    "    phis_obs = data[\"phi\"].to_numpy()\n",
    "    sigmas_obs = data[\"sigma\"].to_numpy()\n",
    "    return times_obs, phis_obs, sigmas_obs\n",
    "\n",
    "def compute_chisq(phis_obs, sigmas_obs, phis_theory):\n",
    "    # Compute chi-squared value\n",
    "    chisq = np.sum((phis_obs - phis_theory) ** 2 / sigmas_obs ** 2)\n",
    "    return chisq\n",
    "\n",
    "def compute_chisqs_params(i, params, times_obs, phis_obs, sigmas_obs, interp_data, phi_bkgs, divisions=100):\n",
    "    # Compute chi-squared values for a single parameter set\n",
    "    chisqs = []\n",
    "    \n",
    "    # Extract the parameters\n",
    "    m, epsilon = params[i]\n",
    "\n",
    "    # Calculate the period in hours\n",
    "    period_hr = mass_to_period(m)\n",
    "\n",
    "    # Generate initial phases\n",
    "    phases = np.linspace(0, period_hr, divisions)\n",
    "\n",
    "    # Get the theoretical best-fit function\n",
    "    delta_phi_func = interp_data[i]\n",
    "\n",
    "    for phase in phases:\n",
    "        # Time shift calculation\n",
    "        times = (times_obs - times_obs[0] + phase) % period_hr\n",
    "        \n",
    "        # Get the theoretical delta phi values\n",
    "        delta_phis = delta_phi_func(times)\n",
    "\n",
    "        # Calculate the theoretical phi values\n",
    "        for phi_bkg in phi_bkgs:\n",
    "            phis_theory = delta_phis + phi_bkg\n",
    "\n",
    "            # Calculate chi-squared values\n",
    "            chisq = compute_chisq(phis_obs, sigmas_obs, phis_theory)\n",
    "            chisqs.append([chisq, phase, phi_bkg])\n",
    "\n",
    "    return chisqs\n",
    "\n",
    "def compute_chisqs_all(params, times_obs, phis_obs, sigmas_obs, interp_data, phi_bkgs, n_jobs=-1, divisions=100):\n",
    "    # Compute chi-squared values for all parameter sets\n",
    "    chisqs_all = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(compute_chisqs_params)(i, params, times_obs, phis_obs, sigmas_obs, interp_data, phi_bkgs, divisions=divisions) \n",
    "        for i in tqdm(range(len(params)))\n",
    "    )\n",
    "\n",
    "    return chisqs_all\n",
    "\n",
    "def extract_chisqs_min(chisqs_all):\n",
    "    # Initialize an empty array to store the results\n",
    "    chisqs_min = np.empty((len(chisqs_all), 3))\n",
    "    \n",
    "    for i in range(len(chisqs_all)):\n",
    "        # Find the index of the minimum chi-squared value for the i-th parameter combination\n",
    "        min_idx = np.argmin(chisqs_all[i][:, 0])\n",
    "\n",
    "        # Store the minimum chi-squared value, the corresponding phase and phi_bkg\n",
    "        chisqs_min[i] = chisqs_all[i][min_idx]\n",
    "    \n",
    "    return chisqs_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the datasets with labels\n",
    "datasets_day81 = {\n",
    "    \"dark\": {\"data\": df_dark_day81, \"label\": \"CARMA\"},\n",
    "    \"blue\": {\"data\": df_blue_day81, \"label\": \"SMTL-CARMAR\"},\n",
    "    \"red\": {\"data\": df_red_day81, \"label\": \"SMTR-CARMAL\"},\n",
    "    \"total\": {\"data\": df_total_day81, \"label\": \"All\"}\n",
    "}\n",
    "\n",
    "datasets_day82 = {\n",
    "    \"dark\": {\"data\": df_dark_day82, \"label\": \"CARMA\"},\n",
    "    \"blue\": {\"data\": df_blue_day82, \"label\": \"SMTL-CARMAR\"},\n",
    "    \"red\": {\"data\": df_red_day82, \"label\": \"SMTR-CARMAL\"},\n",
    "    \"total\": {\"data\": df_total_day82, \"label\": \"All\"}\n",
    "}\n",
    "\n",
    "datasets_day82 = {\"total\": {\"data\": df_total_day82, \"label\": \"All\"}}\n",
    "\n",
    "datasets_total = {\"total\": {\"data\": df_total, \"label\": \"All\"}}\n",
    "\n",
    "# Define the day\n",
    "day = \"8182\"\n",
    "\n",
    "# Define the number of divisions\n",
    "divisions = 100\n",
    "\n",
    "# Define the background phases\n",
    "phi_bkgs = np.linspace(0, 180, divisions)\n",
    "\n",
    "for colour, info in datasets_total.items():\n",
    "    # Define the filename\n",
    "    filename = f\"chisqs_all_{colour}_day{day}.npy\"\n",
    "\n",
    "    # Check if file already exists to avoid recomputing\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"File {filename} already exists. Skipping computation.\")\n",
    "        continue\n",
    "    \n",
    "    data = info[\"data\"]\n",
    "    label = info[\"label\"]\n",
    "    \n",
    "    # Extract observational data\n",
    "    times_obs, phis_obs, sigmas_obs = extract_data_obs(data)\n",
    "    \n",
    "    # Compute chi-squared values for all parameter combinations\n",
    "    chi_sqs_all = compute_chisqs_all(params, times_obs, phis_obs, sigmas_obs, interp_data, phi_bkgs, divisions=divisions)\n",
    "    \n",
    "    # Save the results to a .npy file\n",
    "    np.save(filename, chi_sqs_all)\n",
    "    \n",
    "    print(f\"Saved {filename} for {label}.\")\n",
    "\n",
    "# Load the chi-squared values\n",
    "chisqs_all_total = np.load(f\"chisqs_all_total_day{day}.npy\", allow_pickle=True)\n",
    "\n",
    "# Extract minimum chi-squared values\n",
    "chisqs_min_total = extract_chisqs_min(chisqs_all_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define threshold for 95% CL of one-sided chi-squared distribution of 1 DoF\n",
    "threshold = chi2.ppf(0.95, df=1)\n",
    "\n",
    "# Extract chi-squared values and parameters\n",
    "chisqs_min = chisqs_min_total[:, 0]\n",
    "masses = params[:, 0]\n",
    "epsilons = params[:, 1]\n",
    "\n",
    "# Verify structure of input data\n",
    "unique_masses = np.unique(masses)\n",
    "unique_epsilons = np.unique(epsilons)\n",
    "num_masses = len(unique_masses)\n",
    "num_epsilons = len(unique_epsilons)\n",
    "assert num_masses * num_epsilons == len(params), \"Parameter array size mismatch\"\n",
    "\n",
    "# Reshape data to match unique masses and epsilons\n",
    "chisqs_per_mass = chisqs_min.reshape(num_masses, num_epsilons)\n",
    "epsilons_per_mass = epsilons.reshape(num_masses, num_epsilons)\n",
    "\n",
    "# Compute upper limits\n",
    "chisq_min_per_mass = np.zeros(num_masses)\n",
    "epsilon_min_per_mass = np.zeros(num_masses)\n",
    "upper_limit_epsilons = np.zeros(num_masses)\n",
    "\n",
    "for i in range(num_masses):\n",
    "    chisqs = chisqs_per_mass[i]\n",
    "    epsilons = epsilons_per_mass[i]\n",
    "    \n",
    "    # Find minimum chi-squared and corresponding epsilon\n",
    "    chisq_min_idx = np.argmin(chisqs)\n",
    "    chisq_min = chisqs[chisq_min_idx]\n",
    "    chisq_min_per_mass[i] = chisq_min\n",
    "    epsilon_min = epsilons[chisq_min_idx]\n",
    "    epsilon_min_per_mass[i] = epsilon_min\n",
    "    chisq_threshold = chisq_min + threshold\n",
    "    \n",
    "    # Sort by epsilon in ascending order\n",
    "    sort_idx = np.argsort(epsilons)\n",
    "    epsilons_sorted = epsilons[sort_idx]\n",
    "    chisqs_sorted = chisqs[sort_idx]\n",
    "    \n",
    "    # Find the index of epsilon_min in sorted epsilon array\n",
    "    epsilon_min_idx = np.where(epsilons_sorted == epsilon_min)[0][0]\n",
    "    \n",
    "    # Increase epsilon from epsilon_min until chi-squared exceeds threshold\n",
    "    upper_limit_epsilons[i] = np.nan\n",
    "    for j in range(epsilon_min_idx, len(epsilons_sorted)):\n",
    "        if chisqs_sorted[j] > chisq_threshold:\n",
    "            upper_limit_epsilons[i] = epsilons_sorted[j]\n",
    "            break\n",
    "\n",
    "# Combine and print results\n",
    "results = np.column_stack((unique_masses, chisq_min_per_mass, epsilon_min_per_mass, upper_limit_epsilons))\n",
    "print(\"Mass | Min chi-sq | Min epsilon | 95% CL upper limit on epsilon\")\n",
    "for mass, chisq_min, epsilon_min, epsilon_limit in results:\n",
    "    print(f\"{mass:.2e} | {chisq_min:.4f} | {epsilon_min:.2e} | {epsilon_limit:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for non-NaN values in upper_limit_epsilons\n",
    "mask = ~np.isnan(upper_limit_epsilons)\n",
    "\n",
    "# Filter masses and upper limits\n",
    "valid_masses = unique_masses[mask]\n",
    "valid_upper_limits = upper_limit_epsilons[mask]\n",
    "\n",
    "# Create a log-log plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(np.log10(valid_masses), np.log10(valid_upper_limits), color=\"black\")\n",
    "\n",
    "# Define tick locations (integers and half-integers)\n",
    "x_min, x_max = np.floor(np.log10(valid_masses.min())), np.ceil(np.log10(valid_masses.max()))\n",
    "y_min, y_max = np.floor(np.log10(valid_upper_limits.min())), np.ceil(np.log10(valid_upper_limits.max()))\n",
    "x_ticks = np.arange(x_min, x_max + 0.5, 0.5)\n",
    "y_ticks = np.arange(y_min, y_max + 1, 1)\n",
    "\n",
    "# Set custom tick locators\n",
    "plt.gca().xaxis.set_major_locator(FixedLocator(x_ticks))\n",
    "plt.gca().yaxis.set_major_locator(FixedLocator(y_ticks))\n",
    "\n",
    "# Format tick labels to show integers or half-integers\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(lambda x, pos: f\"{x:.1f}\"))\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, pos: f\"{x:.1f}\"))\n",
    "\n",
    "# Add vertical lines for first and last data points to top edge\n",
    "plt.vlines(np.log10(valid_masses[0]), np.log10(valid_upper_limits[0]), y_max, colors=\"black\")\n",
    "plt.vlines(np.log10(valid_masses[-1]), np.log10(valid_upper_limits[-1]), y_max, colors=\"black\")\n",
    "\n",
    "# Set the limits\n",
    "plt.ylim(y_min, y_max)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(r\"$\\log_{10}(\\mu / \\text{eV})$\", fontsize=12)\n",
    "plt.ylabel(r\"$\\log_{10}(\\epsilon)$\", fontsize=12)\n",
    "\n",
    "# Shade the whole region inside the curve with light green\n",
    "plt.fill_between(np.log10(valid_masses), np.log10(valid_upper_limits), y_max, color=\"lightgreen\", alpha=0.5)\n",
    "\n",
    "# Adjust the spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with multiple subplots\n",
    "fig, axes = plt.subplots(4, 4, figsize=(20, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot chi-squared values against coupling for each mass\n",
    "for i, mass in enumerate(unique_masses):\n",
    "    if i >= len(axes):\n",
    "        break\n",
    "    \n",
    "    # Extract precomputed values for the given mass\n",
    "    chisqs = chisqs_per_mass[i] # Chi-squared values for this mass\n",
    "    epsilons = epsilons_per_mass[i] # Epsilon values for this mass\n",
    "    chisq_min = chisq_min_per_mass[i] # Precomputed minimum chi-squared\n",
    "    epsilon_min = epsilon_min_per_mass[i] # Precomputed epsilon at minimum chi-squared\n",
    "    upper_limit = upper_limit_epsilons[i] # Precomputed 95% CL upper limit on epsilon\n",
    "    \n",
    "    # Compute the threshold for this mass\n",
    "    chisq_threshold = chisq_min + threshold\n",
    "    \n",
    "    # Sort by epsilon in ascending order to find crossing point\n",
    "    sort_idx = np.argsort(epsilons)\n",
    "    epsilons_sorted = epsilons[sort_idx]\n",
    "    chisqs_sorted = chisqs[sort_idx]\n",
    "    min_idx_sorted = np.where(epsilons_sorted == epsilon_min)[0][0]\n",
    "    \n",
    "    # Find the point where chi-squared just exceeds threshold\n",
    "    epsilon_cross = np.nan\n",
    "    chisqs_cross = np.nan\n",
    "    for j in range(min_idx_sorted, len(epsilons_sorted)):\n",
    "        if chisqs_sorted[j] > chisq_threshold:\n",
    "            epsilon_cross = epsilons_sorted[j]\n",
    "            chisqs_cross = chisqs_sorted[j]\n",
    "            break\n",
    "    \n",
    "    # Create plot on the corresponding subplot\n",
    "    axes[i].semilogx(epsilons, chisqs, \"o-\", color=\"blue\", markersize=3)\n",
    "    \n",
    "    # Add horizontal lines at 95% CL threshold and minimum chi-squared\n",
    "    axes[i].axhline(y=chisq_threshold, color=\"r\", linestyle=\"--\", label=r\"95% CL ($\\chi^2_\\text{min}$\"+f\"+{threshold:.2f})\")\n",
    "    axes[i].axhline(y=chisq_min, color=\"g\", linestyle=\"--\", label=r\"$\\chi^2_\\text{min}$\")\n",
    "    \n",
    "    # Highlight min point\n",
    "    axes[i].plot(epsilon_min, chisq_min, \"go\", markersize=5)\n",
    "    \n",
    "    # Circle the point where chi-squared just exceeds threshold\n",
    "    if not np.isnan(epsilon_cross):\n",
    "        axes[i].plot(epsilon_cross, chisqs_cross, \"o\", color=\"purple\", markersize=10, \n",
    "                     markeredgecolor=\"purple\", markerfacecolor=\"none\")\n",
    "    \n",
    "    # Add labels and title\n",
    "    axes[i].set_xlabel(r\"$\\epsilon$\", fontsize=12)\n",
    "    axes[i].set_ylabel(r\"$\\chi^2$\", fontsize=12)\n",
    "    mass_coefficient = mass / 10**np.floor(np.log10(mass))\n",
    "    mass_exponent = int(np.floor(np.log10(mass)))\n",
    "    axes[i].set_title(rf\"$\\mu={mass_coefficient:.2f} \\times 10^{{{mass_exponent}}}$ eV\", fontsize=14)\n",
    "    axes[i].legend(loc=\"upper right\", fontsize=10)\n",
    "\n",
    "# Hide unused subplots\n",
    "for j in range(len(unique_masses), len(axes)):\n",
    "    axes[j].axis(\"off\")\n",
    "\n",
    "# Adjust the spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

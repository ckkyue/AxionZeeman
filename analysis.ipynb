{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FixedLocator, FuncFormatter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from scipy.constants import hbar, physical_constants\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import chi2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Retrieve physical constants\n",
    "e_au = physical_constants[\"atomic unit of charge\"][0]\n",
    "\n",
    "# Conversion factors\n",
    "s_to_eVminus1 = e_au / hbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_to_df(file_path, sigma_value=None):\n",
    "    \"\"\"\n",
    "    Load data from a numpy file and convert it to a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path (str): Path to the numpy file.\n",
    "    - sigma_value (float, optional): Value to use for sigma column if provided.\n",
    "    \n",
    "    Returns:\n",
    "    - df (pd.DataFrame): DataFrame with columns \"time\", \"phi\", and \"sigma\" if specified.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load data from numpy file\n",
    "    data = np.load(file_path)\n",
    "    df = pd.DataFrame(data, columns=[\"time\", \"phi\"])\n",
    "    \n",
    "    # Add sigma column if specified\n",
    "    if sigma_value is not None:\n",
    "        df[\"sigma\"] = sigma_value\n",
    "        \n",
    "    return df\n",
    "\n",
    "def combine_data(df1, df2):\n",
    "    \"\"\"\n",
    "    Combine two DataFrames by averaging their time and phi values.\n",
    "\n",
    "    Parameters:\n",
    "    - df1 (pd.DataFrame): First DataFrame to combine.\n",
    "    - df2 (pd.DataFrame): Second DataFrame to combine.\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame): Combined DataFrame with columns \"time\", \"phi\", and \"sigma\".\n",
    "    \"\"\"\n",
    "\n",
    "    # Combine DataFrames by averaging time and phi values\n",
    "    df = pd.DataFrame({\n",
    "        \"time\": (df1[\"time\"] + df2[\"time\"]) / 2, \n",
    "        \"phi\": (df1[\"phi\"] + df2[\"phi\"]) / 2, \n",
    "        \"sigma\": abs(df1[\"phi\"] - df2[\"phi\"]) / 2\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "def process_day_data(day_folder):\n",
    "    \"\"\"\n",
    "    Process data for a specific day.\n",
    "    \n",
    "    Parameters:\n",
    "    - day_folder (str): Path to the folder containing the day's data.\n",
    "    \n",
    "    Returns:\n",
    "    - df_dark (pd.DataFrame): Dark data DataFrame.\n",
    "    - df_blue (pd.DataFrame): Combined blue data DataFrame.\n",
    "    - df_red (pd.DataFrame): Combined red data DataFrame.\n",
    "    - df_total (pd.DataFrame): Combined total data DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load dark data with fixed sigma\n",
    "    df_dark = load_data_to_df(os.path.join(day_folder, \"dark.npy\"), sigma_value=3)\n",
    "    \n",
    "    # Load blue data\n",
    "    df_blue1 = load_data_to_df(os.path.join(day_folder, \"blue1.npy\"))\n",
    "    df_blue2 = load_data_to_df(os.path.join(day_folder, \"blue2.npy\"))\n",
    "    \n",
    "    # Load red data\n",
    "    df_red1 = load_data_to_df(os.path.join(day_folder, \"red1.npy\"))\n",
    "    df_red2 = load_data_to_df(os.path.join(day_folder, \"red2.npy\"))\n",
    "    \n",
    "    # Create combined blue/red DataFrames\n",
    "    df_blue = combine_data(df_blue1, df_blue2)\n",
    "    df_red = combine_data(df_red1, df_red2)\n",
    "\n",
    "    # Combine and sort all data\n",
    "    df_total = pd.concat([df_dark, df_blue, df_red])\n",
    "    df_total = df_total.sort_values(by=\"time\").reset_index(drop=True)\n",
    "    \n",
    "    return df_dark, df_blue, df_red, df_total\n",
    "\n",
    "def mass_to_period(m):\n",
    "    \"\"\"\n",
    "    Convert mass to period in hours.\n",
    "\n",
    "    Parameters:\n",
    "    - m (float): Mass value in eV.\n",
    "\n",
    "    Returns:\n",
    "    - period_hr (float): Period value in hours.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert mass to period in hours\n",
    "    period_hr = 2 * np.pi / m / s_to_eVminus1 / 3600\n",
    "\n",
    "    return period_hr\n",
    "\n",
    "def period_to_mass(period_hr):\n",
    "    \"\"\"\n",
    "    Convert period to mass in eV.\n",
    "\n",
    "    Parameters:\n",
    "    - period_hr (float): Period value in hours.\n",
    "\n",
    "    Returns:\n",
    "    - m (float): Mass value in eV.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert period to mass in eV\n",
    "    m = 2 * np.pi / period_hr / s_to_eVminus1 / 3600\n",
    "\n",
    "    return m\n",
    "\n",
    "def extract_data_obs(data):\n",
    "    \"\"\"\n",
    "    Extract data from the observation DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): DataFrame containing the observation data.\n",
    "\n",
    "    Returns:\n",
    "    - times_obs (np.ndarray): Array of observation times.\n",
    "    - phis_obs (np.ndarray): Array of observation angles.\n",
    "    - sigmas_obs (np.ndarray): Array of observation errors.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract data from observation\n",
    "    times_obs = data[\"time\"].to_numpy()\n",
    "    phis_obs = data[\"phi\"].to_numpy()\n",
    "    sigmas_obs = data[\"sigma\"].to_numpy()\n",
    "\n",
    "    return times_obs, phis_obs, sigmas_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_polarization(datasets, day):\n",
    "    \"\"\"\n",
    "    Plot the polarization versus time for a given day.\n",
    "\n",
    "    Parameters:\n",
    "    - datasets (dict): Dictionary of labeled datasets.\n",
    "    - day (str): Day to plot the data for.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Extract the dataset for the given day\n",
    "    dataset = datasets[day]\n",
    "\n",
    "    # Plot the polarization versus time for each type\n",
    "    for colour, info in dataset.items():\n",
    "        if colour == \"total\":\n",
    "            continue\n",
    "        elif colour == \"dark\":\n",
    "            color = \"black\"\n",
    "        else:\n",
    "            color = colour\n",
    "        data = info[\"data\"]\n",
    "        label = info[\"label\"]\n",
    "        plt.scatter(data[\"time\"], data[\"phi\"], marker=\"x\", color=color, label=label)\n",
    "        plt.errorbar(data[\"time\"], data[\"phi\"], yerr=data[\"sigma\"], fmt=\"none\", color=color, capsize=5)\n",
    "\n",
    "    # Set the labels and title\n",
    "    plt.xlabel(\"UT Hour\", fontsize=12)\n",
    "    plt.ylabel(r\"Angle ($^\\circ$)\", fontsize=12)\n",
    "    plt.title(f\"Polarization versus Time (Day {day})\", fontsize=14)\n",
    "\n",
    "    # Add a legend\n",
    "    plt.legend(loc=\"upper right\", fontsize=10)\n",
    "\n",
    "    # Adjust the spacing\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "def plot_interp_func(interp_data, i):\n",
    "    \"\"\"\n",
    "    Plot the interpolated function for a given index.\n",
    "\n",
    "    Parameters:\n",
    "    - interp_data (list): List of interpolated functions.\n",
    "    - i (int): Index of the function to plot.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the function\n",
    "    func = interp_data[i]\n",
    "\n",
    "    # Get the x limits\n",
    "    xmin = func.x.min()\n",
    "    xmax = func.x.max()\n",
    "\n",
    "    # Generate x and y values\n",
    "    x = np.linspace(xmin, xmax, 1000)\n",
    "    y = func(x)\n",
    "\n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot the function\n",
    "    plt.plot(x, y)\n",
    "\n",
    "    # Set the labels and title\n",
    "    plt.xlabel(\"Time (hours)\", fontsize=12)\n",
    "    plt.ylabel(r\"$\\Delta \\phi$ (rad)\", fontsize=12)\n",
    "    plt.title(f\"Interpolated Function {i}\", fontsize=14)\n",
    "\n",
    "    # Adjust the spacing\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_chisq(phis_obs, sigmas_obs, phis_theory):\n",
    "    \"\"\"\n",
    "    Compute the chi-squared value for the given observation and theoretical values.\n",
    "    \n",
    "    Parameters:\n",
    "    - phis_obs (np.ndarray): Array of observed angles.\n",
    "    - sigmas_obs (np.ndarray): Array of observed errors.\n",
    "    - phis_theory (np.ndarray): Array of theoretical angles.\n",
    "\n",
    "    Returns:\n",
    "    - chisq (float): Chi-squared value.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute the chi-squared value\n",
    "    chisq = np.sum((phis_obs - phis_theory) ** 2 / sigmas_obs ** 2)\n",
    "\n",
    "    return chisq\n",
    "\n",
    "def compute_chisqs_params(i, params, times_obs, phis_obs, sigmas_obs, interp_data, phi_bkgs, divisions=200):\n",
    "    \"\"\"\n",
    "    Compute chi-squared values for a single set of (m, epsilon) parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    - i (int): Index of the parameter set.\n",
    "    - params (np.ndarray): Array of parameter sets.\n",
    "    - times_obs (np.ndarray): Array of observation times.\n",
    "    - phis_obs (np.ndarray): Array of observation angles.\n",
    "    - sigmas_obs (np.ndarray): Array of observation errors.\n",
    "    - interp_data (list): List of interpolated functions.\n",
    "    - phi_bkgs (np.ndarray): Array of background angles.\n",
    "    - divisions (int, optional): Number of divisions for the period. Default is 200.\n",
    "    \n",
    "    Returns:\n",
    "    - chisqs (list): List of chi-squared values for the parameter set.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute chi-squared values for a single parameter set\n",
    "    chisqs = []\n",
    "    \n",
    "    # Extract the parameters\n",
    "    m, epsilon = params[i]\n",
    "\n",
    "    # Calculate the period in hours\n",
    "    period_hr = mass_to_period(m)\n",
    "\n",
    "    # Generate initial phases\n",
    "    phases = np.linspace(0, period_hr, divisions)\n",
    "\n",
    "    # Get the theoretical best-fit function\n",
    "    delta_phi_func = interp_data[i]\n",
    "\n",
    "    for phase in phases:\n",
    "        # Time shift calculation\n",
    "        times = (times_obs + phase) % period_hr\n",
    "        \n",
    "        # Get the theoretical delta phi values\n",
    "        delta_phis = delta_phi_func(times) * 180 / np.pi\n",
    "\n",
    "        # Normalize the delta phi values\n",
    "        delta_phis = delta_phis - np.mean(delta_phis)\n",
    "\n",
    "        # Calculate the theoretical phi values\n",
    "        for phi_bkg in phi_bkgs:\n",
    "            phis_theory = delta_phis + phi_bkg\n",
    "\n",
    "            # Calculate chi-squared values\n",
    "            chisq = compute_chisq(phis_obs, sigmas_obs, phis_theory)\n",
    "            chisqs.append([chisq, phase, phi_bkg])\n",
    "\n",
    "    return chisqs\n",
    "\n",
    "def compute_chisqs_all(params, times_obs, phis_obs, sigmas_obs, interp_data, phi_bkgs, n_jobs=-1, divisions=200):\n",
    "    \"\"\"\n",
    "    Compute chi-squared values for all parameter sets (m, epsilon).\n",
    "\n",
    "    Parameters:\n",
    "    - params (np.ndarray): Array of parameter sets.\n",
    "    - times_obs (np.ndarray): Array of observation times.\n",
    "    - phis_obs (np.ndarray): Array of observation angles.\n",
    "    - sigmas_obs (np.ndarray): Array of observation errors.\n",
    "    - interp_data (list): List of interpolated functions.\n",
    "    - phi_bkgs (np.ndarray): Array of background angles.\n",
    "    - n_jobs (int, optional): Number of jobs for parallel processing. Default is -1.\n",
    "    - divisions (int, optional): Number of divisions for the period. Default is 200.\n",
    "\n",
    "    Returns:\n",
    "    - chisqs_all (list): List of chi-squared values for all parameter sets.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute chi-squared values for all parameter sets\n",
    "    chisqs_all = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(compute_chisqs_params)(i, params, times_obs, phis_obs, sigmas_obs, interp_data, phi_bkgs, divisions=divisions) \n",
    "        for i in tqdm(range(len(params)))\n",
    "    )\n",
    "\n",
    "    return chisqs_all\n",
    "\n",
    "def extract_chisqs_min(chisqs_all):\n",
    "    \"\"\"\n",
    "    Extract the minimum chi-squared values for all parameter sets.\n",
    "\n",
    "    Parameters:\n",
    "    - chisqs_all (list): List of chi-squared values for all parameter sets.\n",
    "    \n",
    "    Returns:\n",
    "    - chisqs_min (np.ndarray): Array of minimum chi-squared values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize an empty array to store the results\n",
    "    chisqs_min = np.empty((len(chisqs_all), 3))\n",
    "    \n",
    "    for i in range(len(chisqs_all)):\n",
    "        # Find the index of the minimum chi-squared value for the i-th parameter set (m, epsilon)\n",
    "        min_idx = np.argmin(chisqs_all[i][:, 0])\n",
    "\n",
    "        # Store the minimum chi-squared value, the corresponding phase and phi_bkg\n",
    "        chisqs_min[i] = chisqs_all[i][min_idx]\n",
    "    \n",
    "    return chisqs_min\n",
    "\n",
    "def extract_verify_params(params):\n",
    "    \"\"\"\n",
    "    Extract and verify the structure of input parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    - params (np.ndarray): Array of input parameters.\n",
    "    \n",
    "    Returns:\n",
    "    - unique_masses (np.ndarray): Array of unique mass values.\n",
    "    - unique_epsilons (np.ndarray): Array of unique epsilon values.\n",
    "    - num_masses (int): Number of unique mass values.\n",
    "    - num_epsilons (int): Number of unique epsilon values.\n",
    "    - epsilons_per_mass (np.ndarray): Array of epsilon values per mass.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract and verify the structure of input parameters\n",
    "    masses = params[:, 0]\n",
    "    epsilons = params[:, 1]\n",
    "\n",
    "    # Extract unique masses and epsilons\n",
    "    unique_masses = np.unique(masses)\n",
    "    unique_epsilons = np.unique(epsilons)\n",
    "\n",
    "    # Get the number of unique masses and epsilons\n",
    "    num_masses = len(unique_masses)\n",
    "    num_epsilons = len(unique_epsilons)\n",
    "    \n",
    "    # Verify the structure of the input parameters\n",
    "    assert num_masses * num_epsilons == len(params), \"Parameter array size mismatch\"\n",
    "\n",
    "    # Reshape the epsilon values per mass\n",
    "    epsilons_per_mass = epsilons.reshape(num_masses, num_epsilons)\n",
    "    \n",
    "    return unique_masses, unique_epsilons, num_masses, num_epsilons, epsilons_per_mass\n",
    "\n",
    "def compute_epsilon_limits(day, epsilons_per_mass, num_masses, num_epsilons, threshold95, threshold90, scheme=\"grid-search\"):\n",
    "    \"\"\"\n",
    "    Compute the upper limits on epsilon for all mass values.\n",
    "\n",
    "    Parameters:\n",
    "    - day (int): Observation day(s).\n",
    "    - epsilons_per_mass (np.ndarray): Array of epsilon values per mass.\n",
    "    - num_masses (int): Number of unique mass values.\n",
    "    - num_epsilons (int): Number of unique epsilon values.\n",
    "    - threshold95 (float): Threshold for 95% confidence level.\n",
    "    - threshold90 (float): Threshold for 90% confidence level.\n",
    "    - scheme (str, optional): Search scheme. Default is \"grid-search\".\n",
    "\n",
    "    Returns:\n",
    "    - chisqs_per_mass (np.ndarray): Array of chi-squared values per mass.\n",
    "    - chisq_min_per_mass (np.ndarray): Array of minimum chi-squared values per mass.\n",
    "    - epsilon_min_per_mass (np.ndarray): Array of corresponding epsilon values per mass.\n",
    "    - upper_limit_epsilons95 (np.ndarray): Array of 95% CL upper limits on epsilon per mass.\n",
    "    - upper_limit_epsilons90 (np.ndarray): Array of 90% CL upper limits on epsilon per mass.\n",
    "    \"\"\"\n",
    "\n",
    "    if scheme == \"grid-search\":\n",
    "        # Load chi-squared values for the given period\n",
    "        chisqs_all_total = np.load(f\"chisqs_all_total_day{day}.npy\", allow_pickle=True)\n",
    "        chisqs_min_total = extract_chisqs_min(chisqs_all_total)\n",
    "    chisqs_min = chisqs_min_total[:, 0]\n",
    "    chisqs_per_mass = chisqs_min.reshape(num_masses, num_epsilons)\n",
    "    \n",
    "    # Initialize arrays to store results\n",
    "    chisq_min_per_mass = np.zeros(num_masses)\n",
    "    epsilon_min_per_mass = np.zeros(num_masses)\n",
    "    upper_limit_epsilons95 = np.zeros(num_masses)\n",
    "    upper_limit_epsilons90 = np.zeros(num_masses)\n",
    "    \n",
    "    for i in range(num_masses):\n",
    "        # Extract chi-squared values and epsilons for the i-th mass\n",
    "        chisqs = chisqs_per_mass[i]\n",
    "        epsilons = epsilons_per_mass[i]\n",
    "        \n",
    "        # Find the minimum chi-squared value and corresponding epsilon\n",
    "        chisq_min_idx = np.argmin(chisqs)\n",
    "        chisq_min = chisqs[chisq_min_idx]\n",
    "        epsilon_min = epsilons[chisq_min_idx]\n",
    "        \n",
    "        # Store the minimum chi-squared value and corresponding epsilon\n",
    "        chisq_min_per_mass[i] = chisq_min\n",
    "        epsilon_min_per_mass[i] = epsilon_min\n",
    "        \n",
    "        # Compute the threshold chi-squared values for 95% and 90% CL\n",
    "        chisq_threshold95 = chisq_min + threshold95\n",
    "        chisq_threshold90 = chisq_min + threshold90\n",
    "        \n",
    "        # Sort the epsilon values in ascending order\n",
    "        sort_idx = np.argsort(epsilons)\n",
    "        epsilons_sorted = epsilons[sort_idx]\n",
    "        chisqs_sorted = chisqs[sort_idx]\n",
    "        epsilon_min_idx = np.where(epsilons_sorted == epsilon_min)[0][0]\n",
    "\n",
    "        # Find the upper limits on epsilon for 95% and 90% CL\n",
    "        upper_limit_epsilons95[i] = find_upper_limit(epsilons_sorted, chisqs_sorted, epsilon_min_idx, chisq_threshold95)[0]\n",
    "        upper_limit_epsilons90[i] = find_upper_limit(epsilons_sorted, chisqs_sorted, epsilon_min_idx, chisq_threshold90)[0]\n",
    "        \n",
    "    return chisqs_per_mass, chisq_min_per_mass, epsilon_min_per_mass, upper_limit_epsilons95, upper_limit_epsilons90\n",
    "\n",
    "def find_upper_limit(epsilons_sorted, chisqs_sorted, start_idx, threshold):\n",
    "    \"\"\"\n",
    "    Find the upper limit for a given threshold.\n",
    "    \n",
    "    Parameters:\n",
    "    - epsilons_sorted (np.ndarray): Array of sorted epsilon values.\n",
    "    - chisqs_sorted (np.ndarray): Array of sorted chi-squared values.\n",
    "    - start_idx (int): Starting index.\n",
    "    - threshold (float): Threshold value.\n",
    "    \"\"\"    \n",
    "\n",
    "    # Find the upper limit for a given threshold\n",
    "    for j in range(start_idx, len(epsilons_sorted)):\n",
    "        if chisqs_sorted[j] > threshold:\n",
    "            return epsilons_sorted[j], chisqs_sorted[j]\n",
    "        \n",
    "    return np.nan, np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid(x, y):\n",
    "    \"\"\"\n",
    "    Extract valid values from arrays x and y.\n",
    "\n",
    "    Parameters:\n",
    "    - x (np.ndarray): Array of x values.\n",
    "    - y (np.ndarray): Array of y values.\n",
    "\n",
    "    Returns:\n",
    "    - x_valid (np.ndarray): Array of valid x values.\n",
    "    - y_valid (np.ndarray): Array of valid y values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a mask to filter out NaN values\n",
    "    mask = ~np.isnan(y)\n",
    "\n",
    "    return x[mask], y[mask]\n",
    "\n",
    "def plot_epsilon_limits(unique_masses, upper_limit_epsilons95_day82, upper_limit_epsilons90_day82, upper_limit_epsilons95_day81to82, upper_limit_epsilons90_day81to82):\n",
    "    \"\"\"\n",
    "    Plot upper limits on epsilon vs mu for day 82 and day 81 to 82.\n",
    "\n",
    "    Parameters:\n",
    "    - unique_masses (np.ndarray): Array of unique mass values.\n",
    "    - upper_limit_epsilons95_day82 (np.ndarray): 95% CL upper limits on epsilon for day 82.\n",
    "    - pper_limit_epsilons90_day82 (np.ndarray): 90% CL upper limits on epsilon for day 82.\n",
    "    - upper_limit_epsilons95_day81to82 (np.ndarray): 95% CL upper limits on epsilon for day 81 to 82.\n",
    "    - upper_limit_epsilons90_day81to82 (np.ndarray): 90% CL upper limits on epsilon for day 81 to 82.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract valid masses and upper limits for day 82\n",
    "    valid_masses95_day82, valid_upper_limits95_day82 = get_valid(unique_masses, upper_limit_epsilons95_day82)\n",
    "    valid_masses90_day82, valid_upper_limits90_day82 = get_valid(unique_masses, upper_limit_epsilons90_day82)\n",
    "\n",
    "    # Extract valid masses and upper limits for day 81 to 82\n",
    "    valid_masses95_day81to82, valid_upper_limits95_day81to82 = get_valid(unique_masses, upper_limit_epsilons95_day81to82)\n",
    "    valid_masses90_day81to82, valid_upper_limits90_day81to82 = get_valid(unique_masses, upper_limit_epsilons90_day81to82)\n",
    "\n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Plot upper limits for day 82\n",
    "    plt.plot(np.log10(valid_masses95_day82), np.log10(valid_upper_limits95_day82), color=\"blue\", label=\"95% CL (1 Day)\")\n",
    "    plt.plot(np.log10(valid_masses90_day82), np.log10(valid_upper_limits90_day82), color=\"blue\", linestyle=\"--\", label=\"90% CL (1 Day)\")\n",
    "\n",
    "    # Plot upper limits for day 81 to 82\n",
    "    plt.plot(np.log10(valid_masses95_day81to82), np.log10(valid_upper_limits95_day81to82), color=\"red\", label=\"95% CL (2 Days)\")\n",
    "    plt.plot(np.log10(valid_masses90_day81to82), np.log10(valid_upper_limits90_day81to82), color=\"red\", linestyle=\"--\", label=\"90% CL (2 Days)\")\n",
    "\n",
    "    # Combine all valid masses and upper limits\n",
    "    all_valid_masses = np.concatenate([valid_masses95_day82, valid_masses90_day82, valid_masses95_day81to82, valid_masses90_day81to82])\n",
    "    all_valid_limits = np.concatenate([valid_upper_limits95_day82, valid_upper_limits90_day82, valid_upper_limits95_day81to82, valid_upper_limits90_day81to82])\n",
    "    \n",
    "    # Set axis limits and ticks\n",
    "    x_min, x_max = np.floor(np.log10(all_valid_masses.min())) - 0.5, np.floor(np.log10(all_valid_masses.max())) + 0.5\n",
    "    y_min, y_max = np.floor(np.log10(all_valid_limits.min())) - 0.5, 0\n",
    "    x_ticks = np.arange(x_min, x_max + 0.5, 0.5)\n",
    "    y_ticks = np.arange(y_min, y_max + 1, 1)\n",
    "    plt.gca().xaxis.set_major_locator(FixedLocator(x_ticks))\n",
    "    plt.gca().yaxis.set_major_locator(FixedLocator(y_ticks))\n",
    "    plt.gca().xaxis.set_major_formatter(FuncFormatter(lambda x, pos: f\"{x:.1f}\"))\n",
    "    plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, pos: f\"{x:.1f}\"))\n",
    "    plt.ylim(y_min, y_max)\n",
    "\n",
    "    # Add vertical lines at the edges\n",
    "    plt.vlines(np.log10(all_valid_masses[0]), np.log10(all_valid_limits[0]), y_max, colors=\"black\")\n",
    "    plt.vlines(np.log10(all_valid_masses[-1]), np.log10(all_valid_limits[-1]), y_max, colors=\"black\")\n",
    "\n",
    "    # Fill the area between the lines for day 82\n",
    "    plt.fill_between(np.log10(valid_masses95_day82), np.log10(valid_upper_limits95_day82), y_max, color=\"blue\", alpha=0.1)\n",
    "    plt.fill_between(np.log10(valid_masses90_day82), np.log10(valid_upper_limits90_day82), y_max, color=\"blue\", alpha=0.05)\n",
    "\n",
    "    # Fill the area between the lines for day 81 to 82\n",
    "    plt.fill_between(np.log10(valid_masses95_day81to82), np.log10(valid_upper_limits95_day81to82), y_max, color=\"red\", alpha=0.1)\n",
    "    plt.fill_between(np.log10(valid_masses90_day81to82), np.log10(valid_upper_limits90_day81to82), y_max, color=\"red\", alpha=0.05)\n",
    "\n",
    "    # Set the labels and title\n",
    "    plt.xlabel(r\"$\\log_{10}(\\mu / \\text{eV})$\", fontsize=12)\n",
    "    plt.ylabel(r\"$\\log_{10}(\\epsilon)$\", fontsize=12)\n",
    "    plt.title(r\"Upper Limits on Dark Photon-Photon Coupling\", fontsize=14)\n",
    "\n",
    "    # Add a legend\n",
    "    plt.legend(loc=\"lower left\", fontsize=10)\n",
    "\n",
    "    # Adjust the spacing\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "def plot_chisq_coupling(unique_masses, chisqs_per_mass, epsilons_per_mass, chisq_min_per_mass, epsilon_min_per_mass, threshold95, threshold90):\n",
    "    \"\"\"\n",
    "    Plot chi-squared values against coupling for all mass values.\n",
    "    \n",
    "    Parameters:\n",
    "    - unique_masses (np.ndarray): Array of unique mass values.\n",
    "    - chisqs_per_mass (np.ndarray): Array of chi-squared values per mass.\n",
    "    - epsilons_per_mass (np.ndarray): Array of epsilon values per mass.\n",
    "    - chisq_min_per_mass (np.ndarray): Array of minimum chi-squared values per mass.\n",
    "    - epsilon_min_per_mass (np.ndarray): Array of corresponding epsilon values per mass.\n",
    "    - threshold95 (float): Threshold for 95% confidence level.\n",
    "    - threshold90 (float): Threshold for 90% confidence level.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the number of unique masses\n",
    "    num_masses = len(unique_masses)\n",
    "\n",
    "    # Calculate the number of subplots\n",
    "    num_subplots = int(np.ceil(np.sqrt(num_masses)))\n",
    "\n",
    "    # Create a figure with multiple subplots\n",
    "    fig, axes = plt.subplots(num_subplots, num_subplots, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Plot chi-squared values against coupling for each mass on the provided subplots\n",
    "    for i, mass in enumerate(unique_masses):\n",
    "\n",
    "        # Extract precomputed values for the given mass\n",
    "        chisqs = chisqs_per_mass[i]\n",
    "        epsilons = epsilons_per_mass[i]\n",
    "        chisq_min = chisq_min_per_mass[i]\n",
    "        epsilon_min = epsilon_min_per_mass[i]\n",
    "        \n",
    "        # Compute the threshold chi-squared values for 95% and 90% CL\n",
    "        chisq_threshold95 = chisq_min + threshold95\n",
    "        chisq_threshold90 = chisq_min + threshold90\n",
    "        \n",
    "        # Sort the epsilon values in ascending order\n",
    "        sort_idx = np.argsort(epsilons)\n",
    "        epsilons_sorted = epsilons[sort_idx]\n",
    "        chisqs_sorted = chisqs[sort_idx]\n",
    "        min_idx_sorted = np.where(epsilons_sorted == epsilon_min)[0][0]\n",
    "        \n",
    "        # Find the epsilon value where chi-squared just exceeds threshold\n",
    "        epsilon_cross, chisqs_cross = find_upper_limit(epsilons_sorted, chisqs_sorted, min_idx_sorted, chisq_threshold95)\n",
    "        \n",
    "        # Create plot on the corresponding subplot\n",
    "        plot_single_subplot(axes[i], mass, epsilons, epsilon_min, chisqs, chisq_min, threshold95, threshold90, chisq_threshold95, chisq_threshold90, epsilon_cross, chisqs_cross)\n",
    "\n",
    "    # Hide unused subplots in a figure\n",
    "    for j in range(num_masses, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    # Adjust the spacing\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "def plot_single_subplot(ax, mass, epsilons, epsilon_min, chisqs, chisq_min, threshold95, threshold90, chisq_threshold95, chisq_threshold90, epsilon_cross, chisqs_cross):\n",
    "    \"\"\"\n",
    "    Plot chi-squared values against coupling for a single mass on a given subplot.\n",
    "    \n",
    "    Parameters:\n",
    "    - ax (plt.Axes): Subplot to plot on.\n",
    "    - mass (float): Mass value in eV.\n",
    "    - epsilons (np.ndarray): Array of epsilon values.\n",
    "    - epsilon_min (float): Epsilon value corresponding to the minimum chi-squared.\n",
    "    - chisqs (np.ndarray): Array of chi-squared values.\n",
    "    - chisq_min (float): Minimum chi-squared value.\n",
    "    - threshold95 (float): Threshold for 95% CL.\n",
    "    - threshold90 (float): Threshold for 90% CL.\n",
    "    - chisq_threshold95 (float): Threshold chi-squared value for 95% CL.\n",
    "    - chisq_threshold90 (float): Threshold chi-squared value for 90% CL.\n",
    "    - epsilon_cross (float): Epsilon value where chi-squared just exceeds threshold.\n",
    "    - chisqs_cross (float): Chi-squared value where chi-squared just exceeds threshold.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Plot chi-squared values against coupling for a single mass on a given subplot\n",
    "    ax.semilogx(epsilons, chisqs, \"o-\", color=\"blue\", markersize=3)\n",
    "    \n",
    "    # Add horizontal lines at 95% and 90% CL\n",
    "    ax.axhline(y=chisq_threshold95, color=\"r\", linestyle=\"--\", label=r\"95% CL ($\\chi^2_\\text{min}$\"+f\"+{threshold95:.2f})\")\n",
    "    ax.axhline(y=chisq_threshold90, color=\"orange\", linestyle=\"--\", label=r\"90% CL ($\\chi^2_\\text{min}$\"+f\"+{threshold90:.2f})\")\n",
    "\n",
    "    # Add horizontal line at minimum chi-squared\n",
    "    ax.axhline(y=chisq_min, color=\"g\", linestyle=\"--\", label=r\"$\\chi^2_\\text{min}$\")\n",
    "    \n",
    "    # Highlight minimum point\n",
    "    ax.plot(epsilon_min, chisq_min, \"go\", markersize=5)\n",
    "    \n",
    "    # Circle the point where chi-squared just exceeds threshold\n",
    "    if not np.isnan(epsilon_cross):\n",
    "        ax.plot(epsilon_cross, chisqs_cross, \"o\", markersize=10, markeredgecolor=\"red\", markerfacecolor=\"none\")\n",
    "    \n",
    "    # Set the labels and title\n",
    "    ax.set_xlabel(r\"$\\epsilon$\", fontsize=12)\n",
    "    ax.set_ylabel(r\"$\\chi^2$\", fontsize=12)\n",
    "    \n",
    "    # Calculate the mass coefficient and exponent\n",
    "    mass_coefficient = mass / 10**np.floor(np.log10(mass))\n",
    "    mass_exponent = int(np.floor(np.log10(mass)))\n",
    "\n",
    "    # Set the title\n",
    "    ax.set_title(rf\"$\\mu={mass_coefficient:.2f} \\times 10^{{{mass_exponent}}}$ eV\", fontsize=14)\n",
    "\n",
    "    # Add a legend\n",
    "    ax.legend(loc=\"upper right\", fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data folders\n",
    "data_folder = \"sgrdata\"\n",
    "day81_folder = os.path.join(data_folder, \"day81\")\n",
    "day82_folder = os.path.join(data_folder, \"day82\")\n",
    "\n",
    "# Read the pickle file\n",
    "interp_file = os.path.join(data_folder, \"interp_datanew.pkl\")\n",
    "with open(interp_file, \"rb\") as f:\n",
    "    interp_data = pickle.load(f)\n",
    "\n",
    "# Extract the parameters\n",
    "params_data = np.loadtxt(\"paralist_all_SgrltNE.dat\")\n",
    "params = params_data[::20, 1:3]\n",
    "\n",
    "# Process data for day 81 and 82\n",
    "df_dark_day81, df_blue_day81, df_red_day81, df_total_day81 = process_day_data(day81_folder)\n",
    "df_dark_day82, df_blue_day82, df_red_day82, df_total_day82 = process_day_data(day82_folder)\n",
    "\n",
    "# Combine day 81 and day 82 DataFrames\n",
    "df_total_day81to82 = pd.concat([df_total_day81, df_total_day82])\n",
    "df_total_day81to82 = df_total_day81to82.sort_values(by=\"time\").reset_index(drop=True)\n",
    "\n",
    "# Create labeled datasets\n",
    "datasets = {\n",
    "    \"81\": {\n",
    "        \"dark\": {\"data\": df_dark_day81, \"label\": \"CARMA\"},\n",
    "        \"blue\": {\"data\": df_blue_day81, \"label\": \"SMTL-CARMAR\"},\n",
    "        \"red\": {\"data\": df_red_day81, \"label\": \"SMTR-CARMAL\"},\n",
    "        \"total\": {\"data\": df_total_day81, \"label\": \"All\"}\n",
    "        },\n",
    "    \"82\": {\n",
    "        \"dark\": {\"data\": df_dark_day82, \"label\": \"CARMA\"},\n",
    "        \"blue\": {\"data\": df_blue_day82, \"label\": \"SMTL-CARMAR\"},\n",
    "        \"red\": {\"data\": df_red_day82, \"label\": \"SMTR-CARMAL\"},\n",
    "        \"total\": {\"data\": df_total_day82, \"label\": \"All\"}\n",
    "    },\n",
    "    \"81to82\": {\n",
    "        \"total\": {\"data\": df_total_day81to82, \"label\": \"All\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the number of divisions for the period\n",
    "divisions = 200\n",
    "\n",
    "# Define the background phi values\n",
    "phi_bkgs = np.linspace(0, 180, divisions)\n",
    "\n",
    "for colour, info in datasets[\"81to82\"].items():\n",
    "    if colour == \"total\":\n",
    "        # Define the filename\n",
    "        filename = f\"chisqs_all_{colour}_day81to82.npy\"\n",
    "        \n",
    "        # Extract observational data\n",
    "        data = info[\"data\"]\n",
    "        label = info[\"label\"]\n",
    "        times_obs, phis_obs, sigmas_obs = extract_data_obs(data)\n",
    "        \n",
    "        # Check if file already exists to avoid recomputing chi-squared values\n",
    "        if os.path.exists(filename):\n",
    "            print(f\"File {filename} already exists. Skipping computation.\")\n",
    "        else:\n",
    "            # Compute chi-squared values for all parameter combinations\n",
    "            chisqs_all = compute_chisqs_all(params, times_obs, phis_obs, sigmas_obs, interp_data, phi_bkgs, divisions=divisions)\n",
    "\n",
    "            # Save the results to a .npy file\n",
    "            np.save(filename, chisqs_all)\n",
    "            print(f\"Saved {filename} for {label}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the polarization versus time for day 82\n",
    "plot_polarization(datasets, \"82\")\n",
    "\n",
    "# Plot the interpolation function \n",
    "plot_interp_func(interp_data, 839)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define thresholds for 95% and 90% confidence levels\n",
    "threshold95 = chi2.ppf(0.95, df=1)\n",
    "threshold90 = chi2.ppf(0.90, df=1)\n",
    "\n",
    "# Extract and verify the structure of input parameters\n",
    "unique_masses, unique_epsilons, num_masses, num_epsilons, epsilons_per_mass = extract_verify_params(params)\n",
    "\n",
    "# Compute chi-squared values and upper limits on epsilon for day 82 and day 81 to 82\n",
    "_, _, _, upper_limit_epsilons95_day82, upper_limit_epsilons90_day82 = compute_epsilon_limits(\"82\", epsilons_per_mass, num_masses, num_epsilons, threshold95, threshold90)\n",
    "chisqs_per_mass_day81to82, chisq_min_per_mass_day81to82, epsilon_min_per_mass_day81to82, upper_limit_epsilons95_day81to82, upper_limit_epsilons90_day81to82 = compute_epsilon_limits(\"81to82\", epsilons_per_mass, num_masses, num_epsilons, threshold95, threshold90)\n",
    "\n",
    "# Plot upper limits on epsilon for day 82 and day 81 to 82\n",
    "plot_epsilon_limits(unique_masses, upper_limit_epsilons95_day82, upper_limit_epsilons90_day82, upper_limit_epsilons95_day81to82, upper_limit_epsilons90_day81to82)\n",
    "\n",
    "# Plot chi-squared values against coupling for each mass\n",
    "plot_chisq_coupling(unique_masses, chisqs_per_mass_day81to82, epsilons_per_mass, chisq_min_per_mass_day81to82, epsilon_min_per_mass_day81to82, threshold95, threshold90)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
